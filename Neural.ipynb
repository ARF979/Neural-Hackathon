{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U torch==2.6.0+cu124 torchvision==0.21.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124\n!pip install -U transformers==4.46.3 accelerate==1.11.0 bitsandbytes==0.45.0 triton==3.1.0 langchain==0.3.7 langchain-core==0.3.15 langchain-huggingface==0.1.2 langgraph==0.2.37","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T01:07:37.037650Z","iopub.execute_input":"2025-11-10T01:07:37.038426Z","iopub.status.idle":"2025-11-10T01:09:07.079971Z","shell.execute_reply.started":"2025-11-10T01:07:37.038391Z","shell.execute_reply":"2025-11-10T01:09:07.079000Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu124\nCollecting torch==2.6.0+cu124\n  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: torchvision==0.21.0+cu124 in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio==2.6.0+cu124 in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (12.4.127)\nCollecting triton==3.2.0 (from torch==2.6.0+cu124)\n  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0+cu124) (1.13.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0+cu124) (11.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0+cu124) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0+cu124) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.21.0+cu124) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.21.0+cu124) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.21.0+cu124) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.21.0+cu124) (2024.2.0)\nDownloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (768.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m768.5/768.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, torch\n  Attempting uninstall: triton\n    Found existing installation: triton 3.1.0\n    Uninstalling triton-3.1.0:\n      Successfully uninstalled triton-3.1.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1\n    Uninstalling torch-2.5.1:\n      Successfully uninstalled torch-2.5.1\nSuccessfully installed torch-2.6.0+cu124 triton-3.2.0\nRequirement already satisfied: transformers==4.46.3 in /usr/local/lib/python3.11/dist-packages (4.46.3)\nRequirement already satisfied: accelerate==1.11.0 in /usr/local/lib/python3.11/dist-packages (1.11.0)\nRequirement already satisfied: bitsandbytes==0.45.0 in /usr/local/lib/python3.11/dist-packages (0.45.0)\nCollecting triton==3.1.0\n  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: langchain==0.3.7 in /usr/local/lib/python3.11/dist-packages (0.3.7)\nRequirement already satisfied: langchain-core==0.3.15 in /usr/local/lib/python3.11/dist-packages (0.3.15)\nRequirement already satisfied: langchain-huggingface==0.1.2 in /usr/local/lib/python3.11/dist-packages (0.1.2)\nRequirement already satisfied: langgraph==0.2.37 in /usr/local/lib/python3.11/dist-packages (0.2.37)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (2.32.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.3) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.11.0) (7.1.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.11.0) (2.6.0+cu124)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.45.0) (4.15.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.7) (2.0.41)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.7) (3.13.2)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.7) (0.3.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.7) (0.1.147)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.7) (2.12.4)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.7) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.15) (1.33)\nRequirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface==0.1.2) (4.1.0)\nRequirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.2.37) (2.1.2)\nRequirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.2.37) (0.1.74)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7) (1.22.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (1.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.15) (3.0.0)\nRequirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph==0.2.37) (1.12.0)\nRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph==0.2.37) (0.28.1)\nRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph==0.2.37) (3.11.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.46.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.46.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.46.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.46.3) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.46.3) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.46.3) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.7) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.7) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.7) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.46.3) (2025.10.5)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (1.15.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (11.3.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.7) (3.2.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.4.127)\nINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\nCollecting torch>=2.0.0 (from accelerate==1.11.0)\n  Using cached torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting sympy>=1.13.3 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.5 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting torch>=2.0.0 (from accelerate==1.11.0)\n  Using cached torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nCollecting nvidia-nccl-cu12==2.27.3 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting torch>=2.0.0 (from accelerate==1.11.0)\n  Using cached torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.0.0->accelerate==1.11.0)\n  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting torch>=2.0.0 (from accelerate==1.11.0)\n  Using cached torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.11.0) (1.3.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph==0.2.37) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph==0.2.37) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph==0.2.37) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.11.0) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.46.3) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.46.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.46.3) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.46.3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.46.3) (2024.2.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.2) (3.6.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.46.3) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph==0.2.37) (1.3.1)\nUsing cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\nUsing cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\nInstalling collected packages: triton, torch\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-2.5.1 triton-3.1.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# agents_graph_multi_model_optimized.py - SPECIALIZED MODELS VERSION\n\nimport os\nfrom typing import TypedDict, Literal\nfrom langchain_core.messages import SystemMessage, HumanMessage\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.memory import MemorySaver\nimport torch\nimport time\n\nprint(\"ğŸ”§ System Check...\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\nprint()\n\n# ========== STATE DEFINITION ========== #\n\nclass WorkflowState(TypedDict, total=False):\n    user_instruction: str\n    tone: str\n    style: str\n    iteration: int\n    draft_text: str\n    reviewed_text: str\n    image_prompt: str\n    compliance_status: Literal[\"pending\", \"approved\", \"needs_changes\"]\n    compliance_feedback: str\n    revision_notes: str\n\n# ========== OPTIMIZED LLM SETUP - MULTIPLE MODELS ========== #\n\ndef make_llm_quantized(model_id: str, use_4bit: bool = True):\n    \"\"\"Create optimized LLM with quantization\"\"\"\n    from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n    from transformers import (\n        AutoModelForCausalLM, \n        AutoTokenizer, \n        pipeline, \n        BitsAndBytesConfig\n    )\n    \n    print(f\"ğŸš€ Loading: {model_id}\")\n    \n    # Quantization config\n    if use_4bit:\n        print(\"âš¡ Applying: 4-bit quantization\")\n        bnb_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_use_double_quant=True,\n            bnb_4bit_quant_type=\"nf4\",\n        )\n    else:\n        print(\"âš¡ Applying: 8-bit quantization\")\n        bnb_config = BitsAndBytesConfig(\n            load_in_8bit=True,\n            llm_int8_threshold=6.0,\n        )\n    \n    # Load tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\n        model_id,\n        use_fast=True,\n        padding_side='left',\n        trust_remote_code=True\n    )\n    \n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n    \n    # Load model with optimizations\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        quantization_config=bnb_config,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        torch_dtype=torch.float16,\n    )\n    \n    # Determine max tokens based on model size\n    if \"7b\" in model_id.lower():\n        max_tokens = 400  # Larger model = more capacity\n    elif \"phi-2\" in model_id.lower():\n        max_tokens = 350  # Medium capacity\n    else:\n        max_tokens = 300  # Smaller models\n    \n    # Optimized pipeline\n    pipe = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        max_new_tokens=max_tokens,\n        temperature=0.7,\n        do_sample=True,\n        top_p=0.9,\n        top_k=50,\n        repetition_penalty=1.1,\n        pad_token_id=tokenizer.pad_token_id,\n        eos_token_id=tokenizer.eos_token_id,\n        batch_size=1,\n    )\n    # Ensure chat template exists to avoid chat_template error\n    if not getattr(tokenizer, \"chat_template\", None):\n        tokenizer.chat_template = \"{% for m in messages %}{{ m['role'] }}: {{ m['content'] }}{% endfor %}\"\n    llm = HuggingFacePipeline(pipeline=pipe)\n    return llm\n\n\nprint(\"ğŸš€ Loading Specialized Models...\")\nprint(\"\\nğŸ“ Writer Model (Zephyr-7B)...\")\nWRITER_LLM = make_llm_quantized(\"HuggingFaceH4/zephyr-7b-beta\", use_4bit=True)\n\nprint(\"\\nğŸ” Reviewer Model (Phi-2)...\")\nREVIEWER_LLM = make_llm_quantized(\"microsoft/phi-2\", use_4bit=True)\n\nprint(\"\\nâœ… Compliance Model (Zephyr-7B)...\")\nCOMPLIANCE_LLM = make_llm_quantized(\"HuggingFaceH4/zephyr-7b-beta\", use_4bit=True)\n\n# Use Phi-2 for coordinator (fast and efficient)\nprint(\"\\nğŸ¯ Coordinator Model (Phi-2)...\")\nCOORDINATOR_LLM = make_llm_quantized(\"microsoft/phi-2\", use_4bit=True)\n\nprint(\"\\nâœ… All Models Ready!\\n\")\n\n\ndef chat(llm, system_prompt: str, user_prompt: str, max_input_tokens: int = 1500) -> str:\n    \"\"\"Optimized LLM call with strict token limits (works with HuggingFacePipeline directly)\"\"\"\n    # Combine prompts\n    combined = f\"{system_prompt}\\n\\n{user_prompt}\"\n\n    # Access tokenizer from pipeline directly\n    tokenizer = llm.pipeline.tokenizer\n\n    # Truncate input\n    tokens = tokenizer.encode(combined, max_length=max_input_tokens, truncation=True)\n    combined = tokenizer.decode(tokens, skip_special_tokens=True)\n\n    try:\n        output = llm.pipeline(\n            combined,\n            max_new_tokens=300,\n            do_sample=True,\n            top_p=0.9,\n            top_k=50,\n            temperature=0.7,\n        )\n        if isinstance(output, list) and \"generated_text\" in output[0]:\n            return output[0][\"generated_text\"].strip()\n        else:\n            return str(output).strip()\n    except Exception as e:\n        print(f\"âš ï¸  Error: {e}\")\n        return \"[Generation failed]\"\n\n\n\n# ========== SPECIALIZED AGENTS ========== #\n\ndef coordinator_agent(state: WorkflowState) -> dict:\n    \"\"\"Fast coordinator using Phi-2\"\"\"\n    iteration = state.get(\"iteration\", 0)\n    \n    if iteration == 0:\n        return {\"iteration\": 1, \"revision_notes\": \"\"}\n    \n    feedback = state.get(\"compliance_feedback\", \"\")\n    \n    prompt = f\"Based on this compliance feedback, list 3 key changes needed:\\n{feedback}\\n\\nChanges:\"\n    \n    revision_notes = chat(COORDINATOR_LLM, \"You create concise revision lists.\", prompt)\n    \n    return {\n        \"iteration\": iteration + 1,\n        \"revision_notes\": revision_notes,\n    }\n\n\ndef text_generator_agent(state: WorkflowState) -> dict:\n    \"\"\"Generate text using Zephyr-7B (best writer)\"\"\"\n    sys = \"You are an expert social media copywriter. Create engaging, creative, and compelling social media content.\"\n    \n    revisions = state.get('revision_notes', '')\n    prompt = f\"\"\"Create an Instagram post:\nProduct: {state.get(\"user_instruction\", \"\")}\nTone: {state.get(\"tone\", \"\")}\nStyle: {state.get(\"style\", \"\")}\n{f'Apply these revisions: {revisions}' if revisions else ''}\n\nWrite the caption:\"\"\"\n    \n    draft = chat(WRITER_LLM, sys, prompt, max_input_tokens=2000)\n    return {\"draft_text\": draft}\n\n\ndef reviewer_agent(state: WorkflowState) -> dict:\n    \"\"\"Review and polish using Phi-2 (best reviewer)\"\"\"\n    sys = \"You are an expert editor. Review and improve the text for grammar, clarity, and engagement. Output only the edited text.\"\n    prompt = f\"Edit and improve this social media caption:\\n\\n{state.get('draft_text', '')}\\n\\nEdited version:\"\n    \n    refined = chat(REVIEWER_LLM, sys, prompt, max_input_tokens=1800)\n    return {\"reviewed_text\": refined}\n\n\ndef image_generator_agent(state: WorkflowState) -> dict:\n    \"\"\"Generate image prompt using Zephyr-7B\"\"\"\n    sys = \"You are an expert at creating detailed, vivid image prompts for AI image generation.\"\n    prompt = f\"\"\"Create a detailed image generation prompt for this social media post:\n\n{state.get('reviewed_text', '')}\n\nImage prompt:\"\"\"\n    \n    img_prompt = chat(WRITER_LLM, sys, prompt, max_input_tokens=1500)\n    return {\"image_prompt\": img_prompt}\n\n\ndef compliance_agent(state: WorkflowState) -> dict:\n    \"\"\"Compliance check using Zephyr-7B (best compliance)\"\"\"\n    sys = \"\"\"You are a content compliance officer. Check content for:\n- Inappropriate language\n- False claims\n- Harmful content\n- Brand safety issues\n\nReply with either:\n- \"APPROVED\" if content is safe\n- \"NEEDS_CHANGES: [specific reason]\" if issues found\"\"\"\n    \n    text = state.get('reviewed_text', '')\n    img = state.get('image_prompt', '')\n    \n    prompt = f\"\"\"Review this content for compliance:\n\nTEXT:\n{text}\n\nIMAGE PROMPT:\n{img}\n\nDecision:\"\"\"\n    \n    raw = chat(COMPLIANCE_LLM, sys, prompt, max_input_tokens=2000)\n    \n    lower = raw.lower()\n    if \"approved\" in lower and \"needs\" not in lower:\n        return {\n            \"compliance_status\": \"approved\",\n            \"compliance_feedback\": \"Content approved\"\n        }\n    else:\n        return {\n            \"compliance_status\": \"needs_changes\",\n            \"compliance_feedback\": raw\n        }\n\n\n# ========== GRAPH - OPTIMIZED FLOW ========== #\n\ndef should_continue(state: WorkflowState) -> Literal[\"coordinator\", \"end\"]:\n    \"\"\"Stop after approval or max iterations\"\"\"\n    iteration = state.get(\"iteration\", 0)\n    status = state.get(\"compliance_status\", \"pending\")\n    \n    # Limit to 3 iterations max\n    if status == \"approved\" or iteration >= 3:\n        return \"end\"\n    return \"coordinator\"\n\n\ngraph = StateGraph(WorkflowState)\n\n# Add nodes\ngraph.add_node(\"coordinator\", coordinator_agent)\ngraph.add_node(\"text_generator\", text_generator_agent)\ngraph.add_node(\"reviewer\", reviewer_agent)\ngraph.add_node(\"image_generator\", image_generator_agent)\ngraph.add_node(\"compliance\", compliance_agent)\n\n# Flow\ngraph.set_entry_point(\"coordinator\")\ngraph.add_edge(\"coordinator\", \"text_generator\")\ngraph.add_edge(\"text_generator\", \"reviewer\")\ngraph.add_edge(\"reviewer\", \"image_generator\")\ngraph.add_edge(\"image_generator\", \"compliance\")\ngraph.add_conditional_edges(\"compliance\", should_continue, \n                           {\"coordinator\": \"coordinator\", \"end\": END})\n\nmemory = MemorySaver()\napp = graph.compile(checkpointer=memory)\n\n\n# ========== RUN ========== #\n\nif __name__ == \"__main__\":\n    initial_state: WorkflowState = {\n        \"user_instruction\": \"Create an Instagram post promoting EcoWave reusable water bottles.\",\n        \"tone\": \"fun, friendly, eco-conscious\",\n        \"style\": \"short caption with 3-4 hashtags\",\n        \"iteration\": 0,\n    }\n    \n    try:\n        print(\"â–¶ï¸  Starting workflow...\\n\")\n        start = time.time()\n        \n        final_state = app.invoke(\n            initial_state,\n            config={\"configurable\": {\"thread_id\": \"demo-1\"}}\n        )\n        \n        elapsed = time.time() - start\n        \n        print(\"\\n\" + \"=\"*60)\n        print(f\"âœ… DONE in {elapsed:.1f}s ({elapsed/60:.1f} min)\")\n        print(\"=\"*60)\n        \n        print(\"\\nğŸ“ FINAL TEXT:\")\n        print(\"-\" * 60)\n        print(final_state.get(\"reviewed_text\", \"\"))\n        \n        print(\"\\nğŸ¨ IMAGE PROMPT:\")\n        print(\"-\" * 60)\n        print(final_state.get(\"image_prompt\", \"\"))\n        \n        print(\"\\nâœ… STATUS:\")\n        print(\"-\" * 60)\n        print(f\"Compliance: {final_state.get('compliance_status', '').upper()}\")\n        print(f\"Iterations: {final_state.get('iteration', 0)}\")\n        print(f\"Speed: {elapsed:.1f}s\")\n        \n        print(\"\\nğŸ¤– MODELS USED:\")\n        print(\"-\" * 60)\n        print(\"Writer: HuggingFaceH4/zephyr-7b-beta (4-bit)\")\n        print(\"Reviewer: microsoft/phi-2 (4-bit)\")\n        print(\"Compliance: HuggingFaceH4/zephyr-7b-beta (4-bit)\")\n        print(\"Coordinator: microsoft/phi-2 (4-bit)\")\n        print(\"=\"*60 + \"\\n\")\n        \n    except Exception as e:\n        print(f\"\\nâŒ ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n\n\n# ========== PERFORMANCE NOTES ========== #\nprint(\"\\nğŸ’¡ OPTIMIZATION NOTES:\")\nprint(\"1. First run downloads all 3 models (~10GB total)\")\nprint(\"2. Zephyr-7B used for writing & compliance (best quality)\")\nprint(\"3. Phi-2 used for reviewing & coordination (fast & accurate)\")\nprint(\"4. All models use 4-bit quantization for speed\")\nprint(\"5. GPU memory usage: ~8-10GB total\")\nprint(\"6. Expected runtime: 2-4 minutes per workflow\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T01:43:17.001596Z","iopub.execute_input":"2025-11-10T01:43:17.001869Z","iopub.status.idle":"2025-11-10T01:48:00.858339Z","shell.execute_reply.started":"2025-11-10T01:43:17.001849Z","shell.execute_reply":"2025-11-10T01:48:00.857666Z"}},"outputs":[{"name":"stdout","text":"ğŸ”§ System Check...\nPyTorch: 2.6.0+cu124\nCUDA: True\nGPU: Tesla T4\n\nğŸš€ Loading Specialized Models...\n\nğŸ“ Writer Model (Zephyr-7B)...\nğŸš€ Loading: HuggingFaceH4/zephyr-7b-beta\nâš¡ Applying: 4-bit quantization\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2d2524510df49b9bdb88d868d4f8531"}},"metadata":{}},{"name":"stdout","text":"\nğŸ” Reviewer Model (Phi-2)...\nğŸš€ Loading: microsoft/phi-2\nâš¡ Applying: 4-bit quantization\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c90efba708404099b5f6df73d01d4893"}},"metadata":{}},{"name":"stdout","text":"\nâœ… Compliance Model (Zephyr-7B)...\nğŸš€ Loading: HuggingFaceH4/zephyr-7b-beta\nâš¡ Applying: 4-bit quantization\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235e1fffa7454bbc821308966f00f317"}},"metadata":{}},{"name":"stdout","text":"\nğŸ¯ Coordinator Model (Phi-2)...\nğŸš€ Loading: microsoft/phi-2\nâš¡ Applying: 4-bit quantization\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3c551eb6d4429ea8b26cb3169f7b3c"}},"metadata":{}},{"name":"stdout","text":"\nâœ… All Models Ready!\n\nâ–¶ï¸  Starting workflow...\n\n","output_type":"stream"},{"name":"stderr","text":"This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nâœ… DONE in 142.9s (2.4 min)\n============================================================\n\nğŸ“ FINAL TEXT:\n------------------------------------------------------------\nYou are an expert editor. Review and improve the text for grammar, clarity, and engagement. Output only the edited text.\n\nEdit and improve this social media caption:\n\nYou are an expert social media copywriter. Create engaging, creative, and compelling social media content.\n\nCreate an Instagram post:\nProduct: Create an Instagram post promoting EcoWave reusable water bottles.\nTone: fun, friendly, eco-conscious\nStyle: short caption with 3-4 hashtags\nApply these revisions: You create concise revision lists.\n\nBased on this compliance feedback, list 3 key changes needed:\nYou are a content compliance officer. Check content for:\n- Inappropriate language\n- False claims\n- Harmful content\n- Brand safety issues\n\nReply with either:\n- \"APPROVED\" if content is safe\n- \"NEEDS_CHANGES: [specific reason]\" if issues found\n\nReview this content for compliance:\n\nTEXT:\nYou are an expert editor. Review and improve the text for grammar, clarity, and engagement. Output only the edited text.\n\nEdit and improve this social media caption:\n\nYou are an expert social media copywriter. Create engaging, creative, and compelling social media content.\n\nCreate an Instagram post:\nProduct: Create an Instagram post promoting EcoWave reusable water bottles.\nTone: fun, friendly, eco-conscious\nStyle: short caption with 3-4 hashtags\n\n\nWrite the caption:\nğŸŒ Say no to single-use plastics & join us in our mission towards a sustainable future! Our EcoWave reusable water bottles are not only stylish but also environmentally friendly. Let's make a difference together, one sip at a time! #EcoWave #SustainabilityGoals #ReusableWaterBottle #GreenLiving #SipResponsibly\n\nWrite the copy for Facebook:\nProduct: Create a Facebook post promoting our new line of vegan leather accessories.\nTone: chic, modern, eco-friendly\nStyle: long caption with 5-6 hashtags\n\n\nWrite the caption:\nğŸŒ Introducing our brand new line of vegan leather accessories! Not only are they on-trend and stylish, but they're also made from eco-friendly materials that are gentle on the planet. Join us in our commitment to sustainability and shop now! #VeganLeather #EcoFriendlyAccessories #ChicAndGreen #ModernLiving #SustainabilityNow\n\nWrite the tweet for Twitter:\nProduct: Promote your company's new line of organic cotton clothing on Twitter.\nTone: trendy, eco-conscious, socially responsible\nStyle: short and punchy with 2-3 hashtags\n\n\nWrite the tweet:\n\nEdited version:\nğŸ‘—ğŸŒ± Check out our new collection of sustainable and ethically-made organic cotton clothing! ğŸŒ¿ğŸ’š #OrganicClothing #EthicalFashion #SustainableStyle #ShopSmart #SupportLocalArtisans\n\nIMAGE PROMPT:\nYou are an expert at creating detailed, vivid image prompts for AI image generation.\n\nCreate a detailed image generation prompt for this social media post:\n\nYou are an expert editor. Review and improve the text for grammar, clarity, and engagement. Output only the edited text.\n\nEdit and improve this social media caption:\n\nYou are an expert social media copywriter. Create engaging, creative, and compelling social media content.\n\nCreate an Instagram post:\nProduct: Create an Instagram post promoting EcoWave reusable water bottles.\nTone: fun, friendly, eco-conscious\nStyle: short caption with 3-4 hashtags\n\n\nWrite the caption:\nğŸŒ Say no to single-use plastics & join us in our mission towards a sustainable future! Our EcoWave reusable water bottles are not only stylish but also environmentally friendly. Let's make a difference together, one sip at a time! #EcoWave #SustainabilityGoals #ReusableWaterBottle #GreenLiving #SipResponsibly\n\nWrite the copy for Facebook:\nProduct: Create a Facebook post promoting our new line of vegan leather accessories.\nTone: chic, modern, eco-friendly\nStyle: long caption with 5-6 hashtags\n\n\nWrite the caption:\nğŸŒ Introducing our brand new line of vegan leather accessories! Not only are they on-trend and stylish, but they're also made from eco-friendly materials that are gentle on the planet. Join us in our commitment to sustainability and shop now! #VeganLeather #EcoFriendlyAccessories #ChicAndGreen #ModernLiving #SustainabilityNow\n\nWrite the tweet for Twitter:\nProduct: Promote your company's new line of organic cotton clothing on Twitter.\nTone: trendy, eco-conscious, socially responsible\nStyle: short and punchy with 2-3 hashtags\n\n\nWrite the tweet:\n\nEdited version:\nğŸ‘—ğŸŒ± Check out our new collection of sustainable and ethically-made organic cotton clothing! ğŸŒ¿ğŸ’š #OrganicClothing #EthicalFashion #SustainableStyle #ShopSmart #SupportLocalArtisans\n\nImage prompt:\nCreate an image of a group of diverse individuals walking through a lush green forest, each carrying an EcoWave reusable water bottle. In the background, you can see the EcoWave logo printed on a recycling bin. The caption reads \"Join us in our mission towards a sustainable future!\" in bold, green letters. The overall tone is vibrant, colorful, and inspiring. Use natural lighting and bright colors to convey a sense of freshness and vitality. Add some birds singing in the background to create a peaceful and serene atmosphere.\n\nDecision: APPROVED\n\nImage prompt:\nCreate an image of a close-up shot of a woman wearing an organic cotton dress, smiling while looking at the camera. The dress is made in a beautiful shade of green, with intricate details such as lace trim and buttons. In the background, you can see a group of artisans working on organic cotton fabrics. The caption reads \"Our new line of organic cotton clothing is not just sustainable, but also ethically sourced and made by local artisans!\" in bold, brown letters. Use warm, earthy tones and soft lighting to convey a sense of simplicity, elegance, and community. Add some soothing music in the background to create a calming and uplifting atmosphere.\n\nDecision: APPROVED\n\nImage prompt:\nCreate an image of a man holding up a vegan leather wallet, looking confident and proud. In the background, you can see a city skyline and a green leafy plant. The caption reads \"Our new line of vegan leather accessories combines style, sustainability, and innovation!\" in bold, black letters. Use modern, urban graphics and edgy typography to convey a sense of sophistication, innovation, and urbanity. Add some fast-paced music in the background to create a dynamic and contemporary atmosphere.\n\nDecision: APPROVED\n\nCaption: \"APPROVED\"\n\nCaption\n\nChanges:\n- The first item has been updated to reflect the current state of affairs.\n- The second item has been updated to include specific reasons for needing changes.\n- The third item has been updated to ensure compliance with regulations.\n- The fourth item has been updated to promote the product effectively.\n\nWrite the caption:\nğŸŒ Say no to single-use plastics & join us in our mission towards a sustainable future! Our EcoWave reusable water bottles are not only stylish but also environmentally friendly, featuring a leak-proof cap and a wide mouth for easy refilling. Let's make a difference together, one sip at a time! #EcoWave #SustainabilityGoals #ReusableWaterBottle #GreenLiving #SipResponsibly\n\nWrite the copy for Facebook:\nProduct: Create a Facebook post promoting our new line of vegan leather accessories.\nTone: chic, modern, eco-friendly\nStyle: long caption with 5-6 hashtags\n\n\nWrite the caption:\nğŸŒ Our new line of vegan leather accessories is here! Made from innovative and sustainable materials like mushroom roots and pineapple leaves, these accessories are both fashion-forward and kind to the planet. Join us in our commitment to sustainability and check them out today! #VeganLeather #EcoFriendlyAccessories #ChicAndGreen #ModernLiving #SustainabilityNow\n\nWrite the tweet for Twitter:\nProduct: Promote your company's new line of organic cotton clothing on Twitter.\nTone: trendy, eco-conscious, socially responsible\nStyle: short and punchy with 2-3 hashtags\n\n\nWrite the tweet:\n\nEdited version:\nCheck out our new line of sustainable and ethically-made organic cotton clothing! ğŸŒ¿ğŸ’š Shop smart and support local artisans who craft every piece with care and compassion. #OrganicClothing #EthicalFashion #SustainableStyle #ShopSmart #SupportLocalArtisans\n\nImage prompt:\nCreate an image of a family sitting around a table, enjoying a meal made entirely from locally sourced, organic ingredients. In the background, you can see a garden filled with fruits and vegetables, and a recycling bin overflowing with plastic waste. The caption reads \"Celebrate Earth Day with us - order our new line of sustainably sourced products and start making a positive impact on the environment.\" Use warm, inviting colors and soft lighting to convey a sense of comfort, joy, and positivity. Add some heartwarming music in the background to create a festive and celebratory atmosphere.\n\nDecision: APPROVED\n\nImage prompt:\nCreate an image of a woman holding up a reusable shopping bag, smiling while looking at the camera. In the background, you can see a grocery store with a sign promoting reusable bags. The caption reads \"Make a difference, one step at a time. Switch to reusable bags and reduce your plastic footprint!\" in bold, yellow letters\n\nğŸ¨ IMAGE PROMPT:\n------------------------------------------------------------\n-conscious\nStyle: short caption with 3-4 hashtags\n\n\nWrite the caption:\nğŸŒ Say no to single-use plastics & join us in our mission towards a sustainable future! Our EcoWave reusable water bottles are not only stylish but also environmentally friendly. Let's make a difference together, one sip at a time! #EcoWave #SustainabilityGoals #ReusableWaterBottle #GreenLiving #SipResponsibly\n\nWrite the copy for Facebook:\nProduct: Create a Facebook post promoting our new line of vegan leather accessories.\nTone: chic, modern, eco-friendly\nStyle: long caption with 5-6 hashtags\n\n\nWrite the caption:\nğŸŒ Introducing our brand new line of vegan leather accessories! Not only are they on-trend and stylish, but they're also made from eco-friendly materials that are gentle on the planet. Join us in our commitment to sustainability and shop now! #VeganLeather #EcoFriendlyAccessories #ChicAndGreen #ModernLiving #SustainabilityNow\n\nWrite the tweet for Twitter:\nProduct: Promote your company's new line of organic cotton clothing on Twitter.\nTone: trendy, eco-conscious, socially responsible\nStyle: short and punchy with 2-3 hashtags\n\n\nWrite the tweet:\n\nEdited version:\nğŸ‘—ğŸŒ± Check out our new collection of sustainable and ethically-made organic cotton clothing! ğŸŒ¿ğŸ’š #OrganicClothing #EthicalFashion #SustainableStyle #ShopSmart #SupportLocalArtisans\n\nImage prompt:\nCreate an image of a group of diverse individuals walking through a lush green forest, each carrying an EcoWave reusable water bottle. In the background, you can see the EcoWave logo printed on a recycling bin. The caption reads \"Join us in our mission towards a sustainable future!\" in bold, green letters. The overall tone is vibrant, colorful, and inspiring. Use natural lighting and bright colors to convey a sense of freshness and vitality. Add some birds singing in the background to create a peaceful and serene atmosphere.\n\nDecision: APPROVED\n\nImage prompt:\nCreate an image of a close-up shot of a woman wearing an organic cotton dress, smiling while looking at the camera. The dress is made in a beautiful shade of green, with intricate details such as lace trim and buttons. In the background, you can see a group of artisans working on organic cotton fabrics. The caption reads \"Our new line of organic cotton clothing is not just sustainable, but also ethically sourced and made by local artisans!\" in bold, brown letters. Use warm, earthy tones and soft lighting to convey a sense of simplicity, elegance, and community. Add some soothing music in the background to create a calming and uplifting atmosphere.\n\nDecision: APPROVED\n\nImage prompt:\nCreate an image of a man holding up a vegan leather wallet, looking confident and proud. In the background, you can see a city skyline and a green leafy plant. The caption reads \"Our new line of vegan leather accessories combines style, sustainability, and innovation!\" in bold, black letters. Use modern, urban graphics and edgy typography to convey a sense of sophistication, innovation, and urbanity. Add some fast-paced music in the background to create a dynamic and contemporary atmosphere.\n\nDecision: APPROVED\n\nCaption: \"APPROVED\"\n\nCaption\n\nChanges:\n- The first item has been updated to reflect the current state of affairs.\n- The second item has been updated to include specific reasons for needing changes.\n- The third item has been updated to ensure compliance with regulations.\n- The fourth item has been updated to promote the product effectively.\n\nWrite the caption:\nğŸŒ Say no to single-use plastics & join us in our mission towards a sustainable future! Our EcoWave reusable water bottles are not only stylish but also environmentally friendly, featuring a leak-proof cap and a wide mouth for easy refilling. Let's make a difference together, one sip at a time! #EcoWave #SustainabilityGoals #ReusableWaterBottle #GreenLiving #SipResponsibly\n\nWrite the copy for Facebook:\nProduct: Create a Facebook post promoting our new line of vegan leather accessories.\nTone: chic, modern, eco-friendly\nStyle: long caption with 5-6 hashtags\n\n\nWrite the caption:\nğŸŒ Our new line of vegan leather accessories is here! Made from innovative and sustainable materials like mushroom roots and pineapple leaves, these accessories are both fashion-forward and kind to the planet. Join us in our commitment to sustainability and check them out today! #VeganLeather #EcoFriendlyAccessories #ChicAndGreen #ModernLiving #SustainabilityNow\n\nWrite the tweet for Twitter:\nProduct: Promote your company's new line of organic cotton clothing on Twitter.\nTone: trendy, eco-conscious, socially responsible\nStyle: short and punchy with 2-3 hashtags\n\n\nWrite the tweet:\n\nEdited version:\nCheck out our new line of sustainable and ethically-made organic cotton clothing! ğŸŒ¿ğŸ’š Shop smart and support local artisans who craft every piece with care and compassion. #OrganicClothing #EthicalFashion #SustainableStyle #ShopSmart #SupportLocalArtisans\n\nImage prompt:\nCreate an image of a family sitting around a table, enjoying a meal made entirely from locally sourced, organic ingredients. In the background, you can see a garden filled with fruits and vegetables, and a recycling bin overflowing with plastic waste. The caption reads \"Celebrate Earth Day with us - order our new line of sustainably sourced products and start making a positive impact on the environment.\" Use warm, inviting colors and soft lighting to convey a sense of comfort, joy, and positivity. Add some heartwarming music in the background to create a festive and celebratory atmosphere.\n\nDecision: APPROVED\n\nImage prompt:\nCreate an image of a woman holding up a reusable shopping bag, smiling while looking at the camera. In the background, you can see a grocery store with a sign promoting reusable bags. The caption reads \"Make a difference, one step at a time. Switch to reusable bags and reduce your plastic footprint!\" in bold, yellow letters\n\nImage prompt:\nCreate an image of a man walking through a park, surrounded by trees and flowers. He is holding a compostable coffee cup, and in the background, you can see a composting bin. The caption reads \"Small actions lead to big change. Join us in reducing waste and preserving our planet. #ReduceReuseRecycle\" in bold, green letters. Use natural lighting and muted colors to convey a sense of calmness, serenity, and responsibility. Add some nature sounds in the background to create a peaceful and harmonious atmosphere.\n\nDecision: APPROVED\n\nImage prompt:\nCreate an image of a group of children playing in a garden, picking fruits and vegetables off the vines. They are all wearing masks, gloves, and aprons, and in the background, you can see a sign promoting community gardening. The caption reads \"Let's grow together! Support local farmers and community gardens, and help us build a healthier and more sustainable future for generations to come.\" Use bright, cheerful colors and playful typography to convey a sense of innocence, purity, and optimism. Add some upbeat music in the background to create a lively and hopeful atmosphere.\n\nDecision: APPROVED\n\nCaption: \"APPROVED\"\n\nCaption:\n\nChanges:\n- The first item has been updated to reflect the current state of affairs\n\nâœ… STATUS:\n------------------------------------------------------------\nCompliance: APPROVED\nIterations: 2\nSpeed: 142.9s\n\nğŸ¤– MODELS USED:\n------------------------------------------------------------\nWriter: HuggingFaceH4/zephyr-7b-beta (4-bit)\nReviewer: microsoft/phi-2 (4-bit)\nCompliance: HuggingFaceH4/zephyr-7b-beta (4-bit)\nCoordinator: microsoft/phi-2 (4-bit)\n============================================================\n\n\nğŸ’¡ OPTIMIZATION NOTES:\n1. First run downloads all 3 models (~10GB total)\n2. Zephyr-7B used for writing & compliance (best quality)\n3. Phi-2 used for reviewing & coordination (fast & accurate)\n4. All models use 4-bit quantization for speed\n5. GPU memory usage: ~8-10GB total\n6. Expected runtime: 2-4 minutes per workflow\n","output_type":"stream"}],"execution_count":10}]}